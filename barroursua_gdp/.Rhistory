un_file <- file.path(un_path, "un_combined.csv")
bu_file <- file.path(bu_path, "bu_combined.csv")
# Load libraries
library(dplyr)
library(readr)
library(tidyverse)
# Define the file paths laptop
pwt_path <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/pwt_gdp"
mpd_path <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/mpd_gdp"
wdi_path <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/wdi_gdp"
un_path <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/un_gdp"
bu_path <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/barroursua_gdp"
# Define the file paths desktop
#pwt_path <- "/Volumes/ra35wux/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/pwt_gdp"
#mpd_path <- "/Volumes/ra35wux/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/mpd_gdp"
#wdi_path <- "/Volumes/ra35wux/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/wdi_gdp"
# Define the filenames for the PWT datasets
pwt_files <- c("pwt_10.csv", "pwt_10.1.csv", "pwt_9.csv", "pwt_9.1.csv", "pwt_8.csv", "pwt_8.1.csv", "pwt_7.csv",
"pwt_7.1.csv", "pwt_6.3.csv", "pwt_6.2.csv", "pwt_6.1.csv", "pwt_5.6.csv")
# Create full paths for PWT files
pwt_full_paths <- file.path(pwt_path, pwt_files)
# Define the filenames for the MPD datasets
mpd_files <- c("mpd_2010.csv", "mpd_2013.csv", "mpd_2018.csv", "mpd_2020.csv", "mpd_2023.csv")
# Create full paths for MPD files
mpd_full_paths <- file.path(mpd_path, mpd_files)
# Define the filenames for the WDI datasets
wdi_files <- c("wdi_archive.csv", "wdi_data.csv")
# Create full paths for wdi files
wdi_full_paths <- file.path(wdi_path, wdi_files)
# Define the filenames for the un datasets
un_files <- c("un_data.csv")
# Create full paths for un files
un_full_paths <- file.path(un_path, un_files)
# Define the filenames for the bu datasets
bu_files <- c("barro_ursua.csv")
# Create full paths for un files
bu_full_paths <- file.path(bu_path, bu_files)
# Define base years for each dataset ##Add UN here?##
base_years <- list(
"pwt_10" = 2017,
"pwt_10.1" = 2017,
"pwt_9.1" = 2017,
"pwt_9" = 2011,
"pwt_8" = 2011,
"pwt_8.1" = 2005,
"pwt_7" = 2005,
"pwt_7.1" = 2005,
"pwt_6.3" = 2005,
"pwt_6.2" = 2000,
"pwt_6.1" = 1996,
"pwt_5.6" = 1985,
"mpd_2010" = 1990,
"mpd_2013" = 1990,
"mpd_2018" = 2011,
"mpd_2020" = 2011,
"mpd_2023" = 2011,
"wdi_archive" = 2011,
"wdi_data" = 2011,
"un_data" = 2015,
"barro_ursua" = 2006
)
cat("Base Years Content: \n")
print(base_years)
# Set the base year
target_base_year <- 2011
# Function to process datasets based on their type
process_datasets <- function(files, path, source_name, gdp_col, base_years, target_base_year) {
# Debugging output: Show the files received by process_datasets
cat("Files received by process_datasets:", paste(files, collapse = ", "), "\n")
# Process each file
all_data <- bind_rows(lapply(files, function(file) {
# Extract file_basename from file path (file name without extension)
file_basename <- tools::file_path_sans_ext(basename(file))
file_basename <- trimws(file_basename)  # Remove leading/trailing spaces
cat("Processing file:", file, "File basename:", file_basename, "\n")
# Print the base years names and file_basename to compare
cat("Base years names:", names(base_years), "\n")
# Get the base year for this file from the base_years list
if (file_basename %in% names(base_years)) {
dataset_base_year <- base_years[[file_basename]]
cat("Base year for", file_basename, "is", dataset_base_year, "\n")
} else {
cat("Mismatch: No base year found for", file_basename, "\n")
stop("Base year not found for file:", file_basename, "\n")
}
# Read the file
df <- read_csv(file, show_col_types = FALSE)
cat("Read file:", file, "\n")
# Select relevant columns
if (gdp_col %in% colnames(df)) {
df <- df %>%
select(iso3_alpha, year, all_of(gdp_col), country, iso_num, pop) %>%
mutate(version = basename(file))%>%
filter(!is.na(iso3_alpha))
# Convert GDP to numeric
df <- df %>%
mutate(
!!gdp_col := as.numeric(!!sym(gdp_col)),
pop = as.double(pop)
)
# Rebase GDP to the target base year
if (!is.null(dataset_base_year) && dataset_base_year != target_base_year) {
df <- df %>%
mutate(
!!gdp_col := !!sym(gdp_col) * (target_base_year / dataset_base_year)
)
}
# Adjust unit for PWT for standardisation
if (source_name == "PWT") {
df <- df %>%
mutate(
!!gdp_col := !!sym(gdp_col) * 1e6
)
}
# For MPD, convert GDP per capita to total GDP using population
if (source_name == "MPD" && "pop" %in% colnames(df)) {
if ("gdppc" %in% colnames(df)) {
df <- df %>%
mutate(
!!gdp_col := gdppc * (pop * 1000)
)
}
}
return(df)
} else {
warning(paste("Column", gdp_col, "not found in", basename(file)))
return(NULL)
}
}))
# Prioritise the datasets based on the highest version number
prioritised_data <- all_data %>%
mutate(version_num = as.numeric(sub(".*_(\\d+(\\.\\d+)?).*", "\\1", version))) %>%
arrange(desc(version_num)) %>%
group_by(year, iso_num) %>%
summarise(
gdp = first(na.omit(!!sym(gdp_col))),
country = first(country[which.min(is.na(!!sym(gdp_col)))]),
version = first(version),
.groups = 'drop'
) %>%
filter(!is.na(gdp))
return(prioritised_data)
}
# Process PWT datasets
pwt_combined <- process_datasets(pwt_full_paths, pwt_path, "PWT", "rgdpo",  base_years, target_base_year)
write_csv(pwt_combined, file.path(pwt_path, "pwt_combined.csv"))
# Process MPD datasets
mpd_combined <- process_datasets(mpd_full_paths, mpd_path, "MPD", "gdppc",  base_years, target_base_year)
write_csv(mpd_combined, file.path(mpd_path, "mpd_combined.csv"))
# Process WDI datasets
wdi_combined <- process_datasets(wdi_full_paths, wdi_path, "WDI", "GDP_PPP_constant_2011_international_may_2009",  base_years, target_base_year)
write_csv(wdi_combined, file.path(wdi_path, "wdi_combined.csv"))
# Process UN datasets
un_combined <- process_datasets(un_full_paths, un_path, "UN", "gdp_2015_usd",  base_years, target_base_year)
write_csv(un_combined, file.path(un_path, "un_combined.csv"))
# Process UN datasets
bu_combined <- process_datasets(bu_full_paths, un_path, "BU", "gdppc",  base_years, target_base_year)
write_csv(bu_combined, file.path(bu_path, "bu_combined.csv"))
# Print final outputs for verification
print(pwt_combined)
# Check for duplicates
duplicates <- duplicated(pwt_combined[c("iso_num", "year")])
pwt_combined[duplicates, ]
print(mpd_combined)
# Check for duplicates
duplicates <- duplicated(mpd_combined[c("iso_num", "year")])
mpd_combined[duplicates, ]
print(wdi_combined)
# Check for duplicates
duplicates <- duplicated(wdi_combined[c("iso_num", "year")])
wdi_combined[duplicates, ]
print(un_combined)
# Check for duplicates
duplicates <- duplicated(un_combined[c("iso_num", "year")])
un_combined[duplicates, ]
print(bu_combined)
# Check for duplicates
duplicates <- duplicated(bu_combined[c("iso_num", "year")])
bu_combined[duplicates, ]
# File paths for the combined datasets
pwt_file <- file.path(pwt_path, "pwt_combined.csv")
mpd_file <- file.path(mpd_path, "mpd_combined.csv")
wdi_file <- file.path(wdi_path, "wdi_combined.csv")
un_file <- file.path(un_path, "un_combined.csv")
bu_file <- file.path(bu_path, "bu_combined.csv")
# Function to read datasets
read_dataset <- function(file) {
df <- read.csv(file)
return(df)
}
# Read in the datasets
pwt_data <- read_dataset(pwt_file)
mpd_data <- read_dataset(mpd_file)
wdi_data <- read_dataset(wdi_file)
un_data <- read_dataset(un_file)
bu_data <- read_dataset(bu_file)
# Define the hierarchy of datasets: the first dataset has the highest priority
dataset_list <- list(pwt_data, mpd_data, un_data, wdi_data, bu_data) ##
dataset_names <- c("PWT", "MPD", "UN", "WDI", "BU") ##
# Helper function to coalesce safely
safe_gdp_coalesce <- function(df, dataset_name) {
suffixed_gdp_col <- paste0("gdp_", dataset_name)
# Prioritise GDP data
if (dataset_name == "PWT" && suffixed_gdp_col %in% colnames(df)) {
return(df[[suffixed_gdp_col]])
} else if (dataset_name == "MPD" && suffixed_gdp_col %in% colnames(df)) {
return(df[[suffixed_gdp_col]])
} else if (dataset_name == "WDI" && suffixed_gdp_col %in% colnames(df)) {
return(df[[suffixed_gdp_col]])
} else {
return(df[["gdp"]]) #
}
}
# Function to prioritise and combine datasets
combine_datasets <- function(dataset_list, dataset_names) {
# Start with the first dataset
combined_data <- dataset_list[[1]] %>%
mutate(source = dataset_names[1], version = version)
# Loop over remaining datasets and merge them
for (i in 2:length(dataset_list)) {
new_data <- dataset_list[[i]] %>%
mutate(source = dataset_names[i])
# Perform a full join based on iso3_alpha and year
combined_data <- combined_data %>%
full_join(new_data, by = c("iso_num", "year"), suffix = c("", paste0("_", dataset_names[i]))) %>%
# Safely coalesce columns, prioritizing GDP, and version
mutate(
# Prioritize GDP: PWT > MPD > WDI
gdp = coalesce(gdp, !!sym(paste0("gdp_", dataset_names[i]))),
# Prioritize version based on GDP source
version = ifelse(!is.na(gdp), coalesce(version, !!sym(paste0("version_", dataset_names[i]))), version),
# Ensure country is properly carried over
country = coalesce(country, !!sym(paste0("country_", dataset_names[i]))),
# Assign the source based on the available data
source = ifelse(!is.na(gdp), coalesce(source, !!sym(paste0("source_", dataset_names[i]))), source)
) %>%
# Remove the extra suffixed columns
select(-ends_with(paste0("_", dataset_names[i])))
}
return(combined_data)
}
# Combine datasets with prioritisation
combined_data <- combine_datasets(dataset_list, dataset_names)
duplicates <- duplicated(combined_data[c("iso_num", "year")])
if (any(duplicates)) {
cat("Warning: There are still duplicates in the final dataset.\n")
print(combined_data[duplicates, ])
} else {
cat("No duplicates found in the final dataset.\n")
}
# Save the combined dataset to a CSV file
#output_file <- "/Volumes/ra35wux/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/combined_gdp_dataset.csv"
output_file <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/combined_gdp_dataset_test.csv"
write.csv(combined_data, output_file, row.names = FALSE)
# Save the combined dataset to a CSV file
#output_file <- "/Volumes/ra35wux/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/combined_gdp_dataset.csv"
output_file <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/combined_gdp_dataset_test.csv"
write.csv(combined_data, output_file, row.names = FALSE)
print(paste("Combined dataset saved to", output_file))
# Load libraries
library(dplyr)
library(readr)
library(tidyverse)
# Define the file paths laptop
pwt_path <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/pwt_gdp"
mpd_path <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/mpd_gdp"
wdi_path <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/wdi_gdp"
un_path <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/un_gdp"
bu_path <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/barroursua_gdp"
# Define the file paths desktop
#pwt_path <- "/Volumes/ra35wux/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/pwt_gdp"
#mpd_path <- "/Volumes/ra35wux/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/mpd_gdp"
#wdi_path <- "/Volumes/ra35wux/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/wdi_gdp"
# Define the filenames for the PWT datasets
pwt_files <- c("pwt_10.csv", "pwt_10.1.csv", "pwt_9.csv", "pwt_9.1.csv", "pwt_8.csv", "pwt_8.1.csv", "pwt_7.csv",
"pwt_7.1.csv", "pwt_6.3.csv", "pwt_6.2.csv", "pwt_6.1.csv", "pwt_5.6.csv")
# Create full paths for PWT files
pwt_full_paths <- file.path(pwt_path, pwt_files)
# Define the filenames for the MPD datasets
mpd_files <- c("mpd_2010.csv", "mpd_2013.csv", "mpd_2018.csv", "mpd_2020.csv", "mpd_2023.csv")
# Create full paths for MPD files
mpd_full_paths <- file.path(mpd_path, mpd_files)
# Define the filenames for the WDI datasets
wdi_files <- c("wdi_archive.csv", "wdi_data.csv")
# Create full paths for wdi files
wdi_full_paths <- file.path(wdi_path, wdi_files)
# Define the filenames for the un datasets
un_files <- c("un_data.csv")
# Create full paths for un files
un_full_paths <- file.path(un_path, un_files)
# Define the filenames for the bu datasets
bu_files <- c("barro_ursua.csv")
# Create full paths for un files
bu_full_paths <- file.path(bu_path, bu_files)
# Define base years for each dataset ##Add UN here?##
base_years <- list(
"pwt_10" = 2017,
"pwt_10.1" = 2017,
"pwt_9.1" = 2017,
"pwt_9" = 2011,
"pwt_8" = 2011,
"pwt_8.1" = 2005,
"pwt_7" = 2005,
"pwt_7.1" = 2005,
"pwt_6.3" = 2005,
"pwt_6.2" = 2000,
"pwt_6.1" = 1996,
"pwt_5.6" = 1985,
"mpd_2010" = 1990,
"mpd_2013" = 1990,
"mpd_2018" = 2011,
"mpd_2020" = 2011,
"mpd_2023" = 2011,
"wdi_archive" = 2011,
"wdi_data" = 2011,
"un_data" = 2015,
"barro_ursua" = 2006
)
cat("Base Years Content: \n")
print(base_years)
# Set the base year
target_base_year <- 2011
# Function to process datasets based on their type
process_datasets <- function(files, path, source_name, gdp_col, base_years, target_base_year) {
# Debugging output: Show the files received by process_datasets
cat("Files received by process_datasets:", paste(files, collapse = ", "), "\n")
# Process each file
all_data <- bind_rows(lapply(files, function(file) {
# Extract file_basename from file path (file name without extension)
file_basename <- tools::file_path_sans_ext(basename(file))
file_basename <- trimws(file_basename)  # Remove leading/trailing spaces
cat("Processing file:", file, "File basename:", file_basename, "\n")
# Print the base years names and file_basename to compare
cat("Base years names:", names(base_years), "\n")
# Get the base year for this file from the base_years list
if (file_basename %in% names(base_years)) {
dataset_base_year <- base_years[[file_basename]]
cat("Base year for", file_basename, "is", dataset_base_year, "\n")
} else {
cat("Mismatch: No base year found for", file_basename, "\n")
stop("Base year not found for file:", file_basename, "\n")
}
# Read the file
df <- read_csv(file, show_col_types = FALSE)
cat("Read file:", file, "\n")
# Select relevant columns
if (gdp_col %in% colnames(df)) {
df <- df %>%
select(iso3_alpha, year, all_of(gdp_col), country, iso_num, pop) %>%
mutate(version = basename(file))%>%
filter(!is.na(iso3_alpha))
# Convert GDP to numeric
df <- df %>%
mutate(
!!gdp_col := as.numeric(!!sym(gdp_col)),
pop = as.double(pop)
)
# Rebase GDP to the target base year
if (!is.null(dataset_base_year) && dataset_base_year != target_base_year) {
df <- df %>%
mutate(
!!gdp_col := !!sym(gdp_col) * (target_base_year / dataset_base_year)
)
}
# Adjust unit for PWT for standardisation
if (source_name == "PWT") {
df <- df %>%
mutate(
!!gdp_col := !!sym(gdp_col) * 1e6
)
}
# For MPD, convert GDP per capita to total GDP using population
if (source_name == "MPD" && "pop" %in% colnames(df)) {
if ("gdppc" %in% colnames(df)) {
df <- df %>%
mutate(
!!gdp_col := gdppc * (pop * 1000)
)
}
}
return(df)
} else {
warning(paste("Column", gdp_col, "not found in", basename(file)))
return(NULL)
}
}))
# Prioritise the datasets based on the highest version number
prioritised_data <- all_data %>%
mutate(version_num = as.numeric(sub(".*_(\\d+(\\.\\d+)?).*", "\\1", version))) %>%
arrange(desc(version_num)) %>%
group_by(year, iso_num) %>%
summarise(
gdp = first(na.omit(!!sym(gdp_col))),
country = first(country[which.min(is.na(!!sym(gdp_col)))]),
version = first(version),
.groups = 'drop'
) %>%
filter(!is.na(gdp))
return(prioritised_data)
}
# Process PWT datasets
pwt_combined <- process_datasets(pwt_full_paths, pwt_path, "PWT", "rgdpo",  base_years, target_base_year)
write_csv(pwt_combined, file.path(pwt_path, "pwt_combined.csv"))
# Process MPD datasets
mpd_combined <- process_datasets(mpd_full_paths, mpd_path, "MPD", "gdppc",  base_years, target_base_year)
write_csv(mpd_combined, file.path(mpd_path, "mpd_combined.csv"))
# Process WDI datasets
wdi_combined <- process_datasets(wdi_full_paths, wdi_path, "WDI", "GDP_PPP_constant_2011_international_may_2009",  base_years, target_base_year)
write_csv(wdi_combined, file.path(wdi_path, "wdi_combined.csv"))
# Process UN datasets
un_combined <- process_datasets(un_full_paths, un_path, "UN", "gdp_2015_usd",  base_years, target_base_year)
write_csv(un_combined, file.path(un_path, "un_combined.csv"))
# Process UN datasets
bu_combined <- process_datasets(bu_full_paths, un_path, "BU", "gdppc",  base_years, target_base_year)
write_csv(bu_combined, file.path(bu_path, "bu_combined.csv"))
# Print final outputs for verification
print(pwt_combined)
# Check for duplicates
duplicates <- duplicated(pwt_combined[c("iso_num", "year")])
pwt_combined[duplicates, ]
print(mpd_combined)
# Check for duplicates
duplicates <- duplicated(mpd_combined[c("iso_num", "year")])
mpd_combined[duplicates, ]
print(wdi_combined)
# Check for duplicates
duplicates <- duplicated(wdi_combined[c("iso_num", "year")])
wdi_combined[duplicates, ]
print(un_combined)
# Check for duplicates
duplicates <- duplicated(un_combined[c("iso_num", "year")])
un_combined[duplicates, ]
print(bu_combined)
# Check for duplicates
duplicates <- duplicated(bu_combined[c("iso_num", "year")])
bu_combined[duplicates, ]
# File paths for the combined datasets
pwt_file <- file.path(pwt_path, "pwt_combined.csv")
mpd_file <- file.path(mpd_path, "mpd_combined.csv")
wdi_file <- file.path(wdi_path, "wdi_combined.csv")
un_file <- file.path(un_path, "un_combined.csv")
bu_file <- file.path(bu_path, "bu_combined.csv")
# Function to read datasets
read_dataset <- function(file) {
df <- read.csv(file)
return(df)
}
# Read in the datasets
pwt_data <- read_dataset(pwt_file)
mpd_data <- read_dataset(mpd_file)
wdi_data <- read_dataset(wdi_file)
un_data <- read_dataset(un_file)
bu_data <- read_dataset(bu_file)
# Define the hierarchy of datasets: the first dataset has the highest priority
dataset_list <- list(pwt_data, mpd_data, un_data, wdi_data, bu_data) ##
dataset_names <- c("PWT", "MPD", "UN", "WDI", "BU") ##
# Helper function to coalesce safely
safe_gdp_coalesce <- function(df, dataset_name) {
suffixed_gdp_col <- paste0("gdp_", dataset_name)
# Prioritise GDP data
if (dataset_name == "PWT" && suffixed_gdp_col %in% colnames(df)) {
return(df[[suffixed_gdp_col]])
} else if (dataset_name == "MPD" && suffixed_gdp_col %in% colnames(df)) {
return(df[[suffixed_gdp_col]])
} else if (dataset_name == "WDI" && suffixed_gdp_col %in% colnames(df)) {
return(df[[suffixed_gdp_col]])
} else {
return(df[["gdp"]]) #
}
}
# Function to prioritise and combine datasets
combine_datasets <- function(dataset_list, dataset_names) {
# Start with the first dataset
combined_data <- dataset_list[[1]] %>%
mutate(source = dataset_names[1], version = version)
# Loop over remaining datasets and merge them
for (i in 2:length(dataset_list)) {
new_data <- dataset_list[[i]] %>%
mutate(source = dataset_names[i])
# Perform a full join based on iso3_alpha and year
combined_data <- combined_data %>%
full_join(new_data, by = c("iso_num", "year"), suffix = c("", paste0("_", dataset_names[i]))) %>%
# Safely coalesce columns, prioritizing GDP, and version
mutate(
# Prioritize GDP: PWT > MPD > WDI
gdp = coalesce(gdp, !!sym(paste0("gdp_", dataset_names[i]))),
# Prioritize version based on GDP source
version = ifelse(!is.na(gdp), coalesce(version, !!sym(paste0("version_", dataset_names[i]))), version),
# Ensure country is properly carried over
country = coalesce(country, !!sym(paste0("country_", dataset_names[i]))),
# Assign the source based on the available data
source = ifelse(!is.na(gdp), coalesce(source, !!sym(paste0("source_", dataset_names[i]))), source)
) %>%
# Remove the extra suffixed columns
select(-ends_with(paste0("_", dataset_names[i])))
}
return(combined_data)
}
# Combine datasets with prioritisation
combined_data <- combine_datasets(dataset_list, dataset_names)
duplicates <- duplicated(combined_data[c("iso_num", "year")])
if (any(duplicates)) {
cat("Warning: There are still duplicates in the final dataset.\n")
print(combined_data[duplicates, ])
} else {
cat("No duplicates found in the final dataset.\n")
}
# Save the combined dataset to a CSV file
#output_file <- "/Volumes/ra35wux/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/combined_gdp_dataset.csv"
output_file <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/combined_gdp_dataset_test.csv"
write.csv(combined_data, output_file, row.names = FALSE)
print(paste("Combined dataset saved to", output_file))
