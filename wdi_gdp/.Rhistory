cat("Files received by process_datasets:", paste(files, collapse = ", "), "\n")
# Define WDI priority order ## Not currently being applied##
#wdi_files <- c("wdi_archive.csv", "wdi_ppp.csv", "wdi_constant_2015.csv")
# Process each file
all_data <- bind_rows(lapply(files, function(file) {
# Extract file_basename from file path (file name without extension)
file_basename <- tools::file_path_sans_ext(basename(file))
file_basename <- trimws(file_basename)  # Remove leading/trailing spaces
cat("Processing file:", file, " | File basename:", file_basename, "\n")
# Debugging: Check if it exists
if (missing(file_basename) || is.null(file_basename)) {
stop("Error: file_basename is missing or NULL.")
}
# Print available keys in `gdp_type`
cat("Available dataset_info keys:", paste(names(dataset_info), collapse = ", "), "\n")
# Check if file_basename exists in gdp_type
if (!(file_basename %in% names(dataset_info))) {
stop("GDP unit not found for file:", file_basename)
}
gdp_unit <- dataset_info[[file_basename]]$gdp_type  # Get the GDP type
cat("File:", file_basename, " GDP Type:", gdp_unit, "\n")
# Print the base years names and file_basename to compare
cat("Base years names:", names(base_years), "\n")
# Get the base year for this file from the base_years list
if (file_basename %in% names(base_years)) {
dataset_base_year <- base_years[[file_basename]]
cat("Base year for", file_basename, "is", dataset_base_year, "\n")
} else {
cat("Mismatch: No base year found for", file_basename, "\n")
stop("Base year not found for file:", file_basename, "\n")
}
# Get the gdp_type from dataset_info
gdp_type <- dataset_info[[file_basename]]$gdp_type
# Read the file
df <- read_csv(file, show_col_types = FALSE)
cat("Read file:", file, "\n")
# Select relevant columns
if (gdp_col %in% colnames(df)) {
df <- df %>%
select(iso3_alpha, year, all_of(gdp_col), country, iso_num) %>%
mutate(version = basename(file))%>%
filter(!is.na(iso3_alpha))
# Merge with the population data
df <- df %>%
left_join(population_data %>% select(iso_num, year, pop), by = c("iso_num", "year"))
# Convert GDP to numeric
df <- df %>%
mutate(
!!gdp_col := as.numeric(!!sym(gdp_col))
)
# Rebase GDP to the target base year
if (!is.null(dataset_base_year) && dataset_base_year != target_base_year) {
df <- df %>%
mutate(
!!gdp_col := !!sym(gdp_col) * (target_base_year / dataset_base_year)
)
}
#Call adjust_gdp to adjust GDP and GDP per capita based on dataset specifics
df <- adjust_gdp(df, file_basename, gdp_col, gdp_type)  # Calling adjust_gdp
# Convert GDP unit if necessary
convert_gdp <- function(gdp, gdp_type, target_units) {
# Vectorized check for NA and conversion logic
gdp_adjusted <- ifelse(is.na(gdp), NA, gdp * target_units)  # Adjust this line based on your logic for conversion
return(gdp_adjusted)
}
#Call adjust_gdp to adjust GDP and GDP per capita based on dataset specifics
df <- adjust_gdp(df, file_basename, gdp_col, gdp_type)  # Only once
# Add unit column so convert_dataset can work
df$gdp_unit <- dataset_info[[file_basename]]$gdp_unit
# Convert to desired unit (e.g. millions)
df <- convert_dataset(df, target_units)
return(df)
} else {
warning(paste("Column", gdp_col, "not found in", basename(file)))
return(NULL)
}
}))
# Apply prioritisation logic based on dataset type
prioritised_data <- all_data %>%
group_by(iso_num, year) %>%
mutate(version_num = as.numeric(sub(".*_(\\d+(\\.\\d+)?).*", "\\1", version)),
source_order = ifelse(source_name == "WDI", match(version, wdi_files), NA)) %>%
filter(
(source_name %in% c("PWT", "MPD") & version_num == max(version_num)) |
(source_name == "WDI" & (n() == 1 | source_order == min(source_order))) |
!(source_name %in% c("PWT", "MPD", "WDI"))
) %>%
summarise(
country = first(country[which.min(is.na(gdp))]),  # gdp, not gdp_col
gdp = first(na.omit(gdp)),
gdppc = first(na.omit(gdppc)),
version = first(version),
.groups = 'drop'
) %>%
filter(!is.na(gdp))
return(prioritised_data)
}
# Process PWT datasets
pwt_combined <- process_datasets(pwt_full_paths, pwt_path, "PWT", "rgdpo",  base_years, target_base_year)
# Load libraries
library(dplyr)
library(readr)
library(tidyverse)
# Define the file paths laptop
pwt_path <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/pwt_gdp"
mpd_path <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/mpd_gdp"
wdi_path <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/wdi_gdp"
un_path <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/un_gdp"
bu_path <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/barroursua_gdp"
# Load the population dataset
population_path <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/replications/Bermeo/population/combined_pop_dataset.csv"
population_data <- read_csv(population_path)
# Define the file paths desktop
#pwt_path <- "/Volumes/ra35wux/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/pwt_gdp"
#mpd_path <- "/Volumes/ra35wux/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/mpd_gdp"
#wdi_path <- "/Volumes/ra35wux/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/wdi_gdp"
# Define the filenames for the PWT datasets
pwt_files <- c("pwt_10.csv", "pwt_10.1.csv", "pwt_9.csv", "pwt_9.1.csv", "pwt_8.csv", "pwt_8.1.csv", "pwt_7.csv",
"pwt_7.1.csv", "pwt_6.3.csv", "pwt_6.2.csv", "pwt_6.1.csv", "pwt_5.6.csv")
# Create full paths for PWT files
pwt_full_paths <- file.path(pwt_path, pwt_files)
# Define the filenames for the MPD datasets
mpd_files <- c("mpd_2010.csv", "mpd_2013.csv", "mpd_2018.csv", "mpd_2020.csv", "mpd_2023.csv")
# Create full paths for MPD files
mpd_full_paths <- file.path(mpd_path, mpd_files)
# Define the filenames for the WDI datasets
wdi_files <- c("wdi_archive.csv", "wdi_ppp.csv", "wdi_current_lcu_ppp.csv")
# Create full paths for wdi files
wdi_full_paths <- file.path(wdi_path, wdi_files)
# Define the filenames for the un datasets
un_files <- c("un_data_ppp.csv")
# Create full paths for un files
un_full_paths <- file.path(un_path, un_files)
# Define the filenames for the bu datasets
bu_files <- c("barro_ursua.csv")
# Create full paths for un files
bu_full_paths <- file.path(bu_path, bu_files)
# Combined definition for base year, GDP unit, and dataset units
dataset_info <- list(
"pwt_10" = list(base_year = 2017, gdp_unit = "total", gdp_type = "millions"),
"pwt_10.1" = list(base_year = 2017, gdp_unit = "total", gdp_type = "millions"),
"pwt_9.1" = list(base_year = 2017, gdp_unit = "total", gdp_type = "millions"),
"pwt_9" = list(base_year = 2011, gdp_unit = "total", gdp_type = "millions"),
"pwt_8" = list(base_year = 2011, gdp_unit = "total", gdp_type = "millions"),
"pwt_8.1" = list(base_year = 2005, gdp_unit = "total", gdp_type = "millions"),
"pwt_7" = list(base_year = 2005, gdp_unit = "pc", gdp_type = "total"),
"pwt_7.1" = list(base_year = 2005, gdp_unit = "pc", gdp_type = "total"),
"pwt_6.3" = list(base_year = 2005, gdp_unit = "pc", gdp_type = "total"),
"pwt_6.2" = list(base_year = 2000, gdp_unit = "pc", gdp_type = "total"),
"pwt_6.1" = list(base_year = 1996, gdp_unit = "pc", gdp_type = "total"),
"pwt_5.6" = list(base_year = 1985, gdp_unit = "total", gdp_type = "total"),
"mpd_2023" = list(base_year = 2011, gdp_unit = "pc", gdp_type = "total"),
"mpd_2020" = list(base_year = 2011, gdp_unit = "pc",gdp_type = "total"),
"mpd_2018" = list(base_year = 2011, gdp_unit = "pc", gdp_type = "total"),
"mpd_2013" = list(base_year = 1990, gdp_unit = "pc", gdp_type = "total"),
"mpd_2010" = list(base_year = 1990, gdp_unit = "pc", gdp_type = "total"),
"wdi_archive" = list(base_year = 2011, gdp_unit = "total", gdp_type = "total"),
"wdi_ppp" = list(base_year = 2021, gdp_unit = "total", gdp_type = "total"),
"wdi_current_lcu_ppp" = list(base_year = 2015, gdp_unit = "total", gdp_type = "total"),
"un_data_ppp" = list(base_year = 2015, gdp_unit = "total", gdp_type = "total"),
"barro_ursua" = list(base_year = 2006, gdp_unit = "pc", gdp_type = "millions")
)
#Define base years
base_years <- lapply(dataset_info, function(x) x$base_year)
# Set the base year ##
target_base_year <- 2011
# Define the target units globally for GDP ##
target_units <- list(
gdp = "millions"   ## Options: "total", "millions"
)
# Function to adjust GDP between total and per capita
adjust_gdp <- function(df, file_basename, gdp_col, gdp_unit) {
print(paste("Processing file:", file_basename))  # Print to confirm file_basename
print(paste("GDP unit for file:", gdp_unit))  # Check the gdp_unit value
if (!(file_basename %in% names(dataset_info))) {
stop("GDP unit not found for file:", file_basename)
}
#unit_type <- gdp_unit[[file_basename]]  # Get the GDP type- this seems to work with more datasets, so
#left it here as I had to change it
#unit_type <- dataset_info[[file_basename]]$gdp_unit
gdp_unit <- dataset_info[[file_basename]]$gdp_unit
df <- df %>%
mutate(
gdp = case_when(
gdp_unit == "total" ~ !!sym(gdp_col),
gdp_unit == "pc" ~ !!sym(gdp_col) * pop,
TRUE ~ NA_real_
),
gdppc = case_when(
is.na(pop) ~ NA_real_,
gdp_unit == "pc" ~ !!sym(gdp_col),
gdp_unit == "total" ~ !!sym(gdp_col) / pop,
TRUE ~ NA_real_
)
)
return(df)
}
# Function to convert GDP units
convert_gdp <- function(value, from_unit, to_unit) {
if (is.na(value)) {
return(NA)  # If the input value is NA, return NA
}
if (from_unit == to_unit) {
return(value)
} else if (from_unit == "total" && to_unit == "millions") {
return(value / 1e6)
} else if (from_unit == "millions" && to_unit == "total") {
return(value * 1e6)
} else {
stop("Invalid GDP conversion")
}
}
# Function to convert the dataset based on target units
convert_dataset <- function(df, target_units) {
# Debugging output: Check the columns of df
print("Checking dataframe columns:")
print(names(df))
# Ensure columns exist before applying conversion
if (!("gdp" %in% names(df)) | !("gdp_unit" %in% names(df))) {
stop("Error: 'gdp' or 'gdp_unit' columns are missing in the dataframe.")
}
# For GDP conversion
print("Converting GDP...")
df$gdp <- mapply(convert_gdp, df$gdp, df$gdp_unit, MoreArgs = list(target_unit = target_units$gdp))
# Omit rows where either GDP or population is NA, but keep rows where only one value is missing
df <- df[!is.na(df$gdp)]
return(df)
}
# Function to process datasets based on their type
process_datasets <- function(files, path, source_name, gdp_col, base_years, target_base_year) {
# Debugging output: Show the files received by process_datasets
cat("Files received by process_datasets:", paste(files, collapse = ", "), "\n")
# Define WDI priority order ## Not currently being applied##
#wdi_files <- c("wdi_archive.csv", "wdi_ppp.csv", "wdi_constant_2015.csv")
# Process each file
all_data <- bind_rows(lapply(files, function(file) {
# Extract file_basename from file path (file name without extension)
file_basename <- tools::file_path_sans_ext(basename(file))
file_basename <- trimws(file_basename)  # Remove leading/trailing spaces
cat("Processing file:", file, " | File basename:", file_basename, "\n")
# Debugging: Check if it exists
if (missing(file_basename) || is.null(file_basename)) {
stop("Error: file_basename is missing or NULL.")
}
# Print available keys in `gdp_unit`
cat("Available dataset_info keys:", paste(names(dataset_info), collapse = ", "), "\n")
# Check if file_basename exists in gdp_unit
if (!(file_basename %in% names(dataset_info))) {
stop("GDP unit not found for file:", file_basename)
}
gdp_type <- dataset_info[[file_basename]]$gdp_unit  # Get the GDP type
cat("File:", file_basename, " GDP Type:", gdp_type, "\n")
# Print the base years names and file_basename to compare
cat("Base years names:", names(base_years), "\n")
# Get the base year for this file from the base_years list
if (file_basename %in% names(base_years)) {
dataset_base_year <- base_years[[file_basename]]
cat("Base year for", file_basename, "is", dataset_base_year, "\n")
} else {
cat("Mismatch: No base year found for", file_basename, "\n")
stop("Base year not found for file:", file_basename, "\n")
}
# Get the gdp_unit from dataset_info
gdp_unit <- dataset_info[[file_basename]]$gdp_unit
# Read the file
df <- read_csv(file, show_col_types = FALSE)
cat("Read file:", file, "\n")
# Select relevant columns
if (gdp_col %in% colnames(df)) {
df <- df %>%
select(iso3_alpha, year, all_of(gdp_col), country, iso_num) %>%
mutate(version = basename(file))%>%
filter(!is.na(iso3_alpha))
# Merge with the population data
df <- df %>%
left_join(population_data %>% select(iso_num, year, pop), by = c("iso_num", "year"))
# Convert GDP to numeric
df <- df %>%
mutate(
!!gdp_col := as.numeric(!!sym(gdp_col))
)
# Rebase GDP to the target base year
if (!is.null(dataset_base_year) && dataset_base_year != target_base_year) {
df <- df %>%
mutate(
!!gdp_col := !!sym(gdp_col) * (target_base_year / dataset_base_year)
)
}
#Call adjust_gdp to adjust GDP and GDP per capita based on dataset specifics
df <- adjust_gdp(df, file_basename, gdp_col, gdp_unit)  # Calling adjust_gdp
# Convert GDP unit if necessary
convert_gdp <- function(gdp, gdp_unit, target_units) {
# Vectorized check for NA and conversion logic
gdp_adjusted <- ifelse(is.na(gdp), NA, gdp * target_units)  # Adjust this line based on your logic for conversion
return(gdp_adjusted)
}
return(df)
} else {
warning(paste("Column", gdp_col, "not found in", basename(file)))
return(NULL)
}
}))
# Apply prioritisation logic based on dataset type
prioritised_data <- all_data %>%
group_by(iso_num, year) %>%
mutate(version_num = as.numeric(sub(".*_(\\d+(\\.\\d+)?).*", "\\1", version)),
source_order = ifelse(source_name == "WDI", match(version, wdi_files), NA)) %>%
filter(
(source_name %in% c("PWT", "MPD") & version_num == max(version_num)) |
(source_name == "WDI" & (n() == 1 | source_order == min(source_order))) |
!(source_name %in% c("PWT", "MPD", "WDI"))
) %>%
summarise(
country = first(country[which.min(is.na(gdp))]),  # gdp, not gdp_col
gdp = first(na.omit(gdp)),
gdppc = first(na.omit(gdppc)),
version = first(version),
.groups = 'drop'
) %>%
filter(!is.na(gdp))
return(prioritised_data)
}
# Process PWT datasets
pwt_combined <- process_datasets(pwt_full_paths, pwt_path, "PWT", "rgdpo",  base_years, target_base_year)
write_csv(pwt_combined, file.path(pwt_path, "pwt_combined.csv"))
# Process MPD datasets
mpd_combined <- process_datasets(mpd_full_paths, mpd_path, "MPD", "gdppc",  base_years, target_base_year)
write_csv(mpd_combined, file.path(mpd_path, "mpd_combined.csv"))
# Process WDI datasets
wdi_combined <- process_datasets(wdi_full_paths, wdi_path, "WDI", "gdp",  base_years, target_base_year)
write_csv(wdi_combined, file.path(wdi_path, "wdi_combined.csv"))
# Process UN datasets
un_combined <- process_datasets(un_full_paths, un_path, "UN", "gdp_2015_ppp",  base_years, target_base_year)
write_csv(un_combined, file.path(un_path, "un_combined.csv"))
# Process BU datasets
bu_combined <- process_datasets(bu_full_paths, bu_path, "BU", "gdppc",  base_years, target_base_year)
write_csv(bu_combined, file.path(bu_path, "bu_combined.csv"))
# Print final outputs for verification
print(pwt_combined)
# Check for duplicates
duplicates <- duplicated(pwt_combined[c("iso_num", "year")])
pwt_combined[duplicates, ]
print(mpd_combined)
# Check for duplicates
duplicates <- duplicated(mpd_combined[c("iso_num", "year")])
mpd_combined[duplicates, ]
print(wdi_combined)
# Check for duplicates
duplicates <- duplicated(wdi_combined[c("iso_num", "year")])
wdi_combined[duplicates, ]
print(un_combined)
# Check for duplicates
duplicates <- duplicated(un_combined[c("iso_num", "year")])
un_combined[duplicates, ]
print(bu_combined)
# Check for duplicates
duplicates <- duplicated(bu_combined[c("iso_num", "year")])
bu_combined[duplicates, ]
# File paths for the combined datasets
pwt_file <- file.path(pwt_path, "pwt_combined.csv")
mpd_file <- file.path(mpd_path, "mpd_combined.csv")
wdi_file <- file.path(wdi_path, "wdi_combined.csv")
un_file <- file.path(un_path, "un_combined.csv")
bu_file <- file.path(bu_path, "bu_combined.csv")
# Function to read datasets
read_dataset <- function(file) {
df <- read.csv(file)
return(df)
}
# Read in the datasets
pwt_data <- read_dataset(pwt_file)
mpd_data <- read_dataset(mpd_file)
wdi_data <- read_dataset(wdi_file)
un_data <- read_dataset(un_file)
bu_data <- read_dataset(bu_file)
# Define the hierarchy of datasets: the first dataset has the highest priority
dataset_list <- list(mpd_data, pwt_data, wdi_data, un_data, bu_data) ##
dataset_names <- c("MPD", "PWT", "WDI", "UN", "BU") ##
# Helper function to coalesce safely with extended prioritization
safe_gdp_coalesce <- function(df, dataset_name) {
suffixed_gdp_col <- paste0("gdp_", dataset_name)
# Check and prioritise GDP columns from the datasets
if (dataset_name == "PWT" && suffixed_gdp_col %in% colnames(df)) {
return(df[[suffixed_gdp_col]])
} else if (dataset_name == "MPD" && suffixed_gdp_col %in% colnames(df)) {
return(df[[suffixed_gdp_col]])
} else if (dataset_name == "UN" && suffixed_gdp_col %in% colnames(df)) {
return(df[[suffixed_gdp_col]])
} else if (dataset_name == "WDI" && suffixed_gdp_col %in% colnames(df)) {
return(df[[suffixed_gdp_col]])
} else if (dataset_name == "BU" && suffixed_gdp_col %in% colnames(df)) {
return(df[[suffixed_gdp_col]])
} else {
return(df[["gdp"]]) # Fallback if no specific GDP column is found
}
}
# Function to prioritise and combine datasets
combine_datasets <- function(dataset_list, dataset_names) {
# Start with the first dataset
combined_data <- dataset_list[[1]] %>%
mutate(source = dataset_names[1], version = version)
# Loop over remaining datasets and merge them
for (i in 2:length(dataset_list)) {
new_data <- dataset_list[[i]] %>%
mutate(source = dataset_names[i])
# Perform a full join based on iso3_alpha and year
combined_data <- combined_data %>%
full_join(new_data, by = c("iso_num", "year"), suffix = c("", paste0("_", dataset_names[i]))) %>%
# Safely coalesce columns, prioritizing GDP, and version
mutate(
# Prioritize GDP: PWT > MPD > WDI
gdp = coalesce(gdp, !!sym(paste0("gdp_", dataset_names[i]))),
gdppc = coalesce(gdppc, !!sym(paste0("gdppc_", dataset_names[i]))),
# Prioritize version based on GDP source
version = ifelse(!is.na(gdp), coalesce(version, !!sym(paste0("version_", dataset_names[i]))), version),
# Ensure country is properly carried over
country = coalesce(country, !!sym(paste0("country_", dataset_names[i]))),
# Assign the source based on the available data
source = ifelse(!is.na(gdp), coalesce(source, !!sym(paste0("source_", dataset_names[i]))), source)
) %>%
# Remove the extra suffixed columns
select(-ends_with(paste0("_", dataset_names[i])))
}
return(combined_data)
}
# Combine datasets with prioritisation
combined_data <- combine_datasets(dataset_list, dataset_names)
duplicates <- duplicated(combined_data[c("iso_num", "year")])
if (any(duplicates)) {
cat("Warning: There are still duplicates in the final dataset.\n")
print(combined_data[duplicates, ])
} else {
cat("No duplicates found in the final dataset.\n")
}
##Extrapolation
# Create the extrapolation instruction data frame
countries_to_extrapolate <- data.frame(
iso_num = c(92,
116,
184,
279,
308,
462,
520,
586,
591,
659),
start_year = c(1967,
1949,
1965,
1945,
1967,
1965,
1966,
1947,
1903,
1967)
)
# Extrapolation function for a single country's data
extrapolate_GDP_GDPpc <- function(country_data, start_year_target) {
country_data <- country_data %>% arrange(year)
earliest_year <- min(country_data$year)
if (earliest_year <= start_year_target) {
return(country_data)  # No extrapolation needed
}
years_to_add <- (start_year_target):(earliest_year - 1)
n <- length(years_to_add)
# Estimate growth rates using first 5 years
subset_data <- country_data %>% slice(1:5)
gdp_lm <- lm(log(gdp) ~ year, data = subset_data)
gdppc_lm <- lm(log(gdppc) ~ year, data = subset_data)
predicted_gdp <- exp(predict(gdp_lm, newdata = data.frame(year = years_to_add)))
predicted_gdppc <- exp(predict(gdppc_lm, newdata = data.frame(year = years_to_add)))
extrapolated <- tibble(
iso_num = unique(country_data$iso_num),
year = years_to_add,
country = unique(country_data$country),
gdp = predicted_gdp,
gdppc = predicted_gdppc,
version = "extrapolated",
source = "extrapolated"
)
# Combine and return
bind_rows(extrapolated, country_data) %>% arrange(year)
}
# Apply extrapolation country by country (base R + dplyr)
extrapolated_data <- do.call(bind_rows, lapply(split(countries_to_extrapolate,
countries_to_extrapolate$iso_num), function(row) {
iso <- row$iso_num
start_year <- row$start_year
country_df <- combined_data %>% filter(iso_num == iso)
if (nrow(country_df) == 0) return(NULL)
extrapolate_GDP_GDPpc(country_df, start_year)
}))
# View the final extrapolated data
print(extrapolated_data)
new_data <- anti_join(extrapolated_data, combined_data, by = c("iso_num", "year"))
combined_data <- bind_rows(combined_data, new_data)
# Check for duplicates after combining
duplicates <- duplicated(combined_data[c("iso_num", "year")])
if (any(duplicates)) {
cat("Warning: There are still duplicates in the final dataset.\n")
print(combined_data[duplicates, ])
} else {
cat("No duplicates found in the final dataset.\n")
}
# Print final output for verification
print(combined_data)
# Save the combined dataset to a CSV file
#output_file <- "/Volumes/ra35wux/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/combined_gdp_dataset.csv"
output_file <- "H:/Documents/PhD/1 Thesis/Selection bias chapter/full_gdp_datasets/gdp_dataset/combined_gdp_dataset_test.csv"
write.csv(combined_data, output_file, row.names = FALSE)
